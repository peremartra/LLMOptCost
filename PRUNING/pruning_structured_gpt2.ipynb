{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM30TJzZEhObkVrTmDL+PUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "685acf5ba2544455a21cc692e8ea3df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca5801f3a20f4fe2a077826514482406",
              "IPY_MODEL_b79f441aa396408ea1efb2268900b0ff",
              "IPY_MODEL_440c20eae7354d36a746cdc14bd56a56"
            ],
            "layout": "IPY_MODEL_de544659a0604a46a360d75846c8595c"
          }
        },
        "ca5801f3a20f4fe2a077826514482406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f027cbb89d64ad1b07e5bb2ac48cbf7",
            "placeholder": "​",
            "style": "IPY_MODEL_a2ef8a9342c74f00ada72ccdb0fc6ef1",
            "value": "model.safetensors: 100%"
          }
        },
        "b79f441aa396408ea1efb2268900b0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56becc351a8c4742a8b7a37b7f5aa387",
            "max": 1995339680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00e9d9927f8545d79cc0bd164a208975",
            "value": 1995339680
          }
        },
        "440c20eae7354d36a746cdc14bd56a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d19de2e86494b16bf29e829cfc8b33c",
            "placeholder": "​",
            "style": "IPY_MODEL_8a933f0153bc4fe68b48fe038dba5a6a",
            "value": " 2.00G/2.00G [00:45&lt;00:00, 39.7MB/s]"
          }
        },
        "de544659a0604a46a360d75846c8595c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f027cbb89d64ad1b07e5bb2ac48cbf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ef8a9342c74f00ada72ccdb0fc6ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56becc351a8c4742a8b7a37b7f5aa387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e9d9927f8545d79cc0bd164a208975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d19de2e86494b16bf29e829cfc8b33c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a933f0153bc4fe68b48fe038dba5a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73686db455224648b2819a4e23b319eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b6ff4523fac43408eec5d727bdbee57",
              "IPY_MODEL_6a60f4ed522348218b828f9c47562343",
              "IPY_MODEL_d7e11345f097435091354b4601a91b89"
            ],
            "layout": "IPY_MODEL_41d196f1d24643f39358fe825a30a8df"
          }
        },
        "8b6ff4523fac43408eec5d727bdbee57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81857adb0d09419c87b0ebe10a333e6d",
            "placeholder": "​",
            "style": "IPY_MODEL_9ee17e7f6c2d438eabdef904f9f496b1",
            "value": "README.md: 100%"
          }
        },
        "6a60f4ed522348218b828f9c47562343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae2f9ced51d24f3096fbf6e433f2902c",
            "max": 5174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a481227d953469880ad36d7d0e3158e",
            "value": 5174
          }
        },
        "d7e11345f097435091354b4601a91b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34c6272fa9ad4ba794f53df49aee5147",
            "placeholder": "​",
            "style": "IPY_MODEL_22f6215920bf4582984c5b8c849e659f",
            "value": " 5.17k/5.17k [00:00&lt;00:00, 349kB/s]"
          }
        },
        "41d196f1d24643f39358fe825a30a8df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81857adb0d09419c87b0ebe10a333e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee17e7f6c2d438eabdef904f9f496b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae2f9ced51d24f3096fbf6e433f2902c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a481227d953469880ad36d7d0e3158e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34c6272fa9ad4ba794f53df49aee5147": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f6215920bf4582984c5b8c849e659f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa7282710eec4628b0da9a5805f27237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_864d67e6afe942799587015cf73db00d",
              "IPY_MODEL_aa450c130f13414e94038ba8231f946c",
              "IPY_MODEL_1d65b561ad324018a31bb79e6f1350b7"
            ],
            "layout": "IPY_MODEL_eb56d4a9d8e442a483bdba3a979b6e53"
          }
        },
        "864d67e6afe942799587015cf73db00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c4da1a8e284c27a46e428a7bb5c107",
            "placeholder": "​",
            "style": "IPY_MODEL_ee05cc45ecda4deb9fd7d9cc184f6fbd",
            "value": "tokenizer.json: 100%"
          }
        },
        "aa450c130f13414e94038ba8231f946c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b759d0fcc2404925b14d795db4dc5f2d",
            "max": 14500499,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2a65814cb514e4a9e250b906ac08502",
            "value": 14500499
          }
        },
        "1d65b561ad324018a31bb79e6f1350b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bac4279ff7bf4da6b9dd26d947565f54",
            "placeholder": "​",
            "style": "IPY_MODEL_803da2ce0315404b8d553c9b69ccfeea",
            "value": " 14.5M/14.5M [00:00&lt;00:00, 119MB/s]"
          }
        },
        "eb56d4a9d8e442a483bdba3a979b6e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c4da1a8e284c27a46e428a7bb5c107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee05cc45ecda4deb9fd7d9cc184f6fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b759d0fcc2404925b14d795db4dc5f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a65814cb514e4a9e250b906ac08502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bac4279ff7bf4da6b9dd26d947565f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803da2ce0315404b8d553c9b69ccfeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ce2504d701e47fdbff6c06392ca2446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_285d6f8cad0741669d72ce3374e1fcab",
              "IPY_MODEL_23180435a0d44201bfe21bb8a8571f49",
              "IPY_MODEL_50422043150a47a8995d442b36a83270"
            ],
            "layout": "IPY_MODEL_bc5d0ad4dec14e179a4992835d899875"
          }
        },
        "285d6f8cad0741669d72ce3374e1fcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9780acc95b524818967bfbf8d5f2c3be",
            "placeholder": "​",
            "style": "IPY_MODEL_c366c4118f8646e5b6d4bc85e8f668f6",
            "value": "config.json: 100%"
          }
        },
        "23180435a0d44201bfe21bb8a8571f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5420eab264d347a6a1282ae06199aa27",
            "max": 836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31b6c9555a2c4c37abdcd77b279d329a",
            "value": 836
          }
        },
        "50422043150a47a8995d442b36a83270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc54375fda694fbbba7187d1374115dc",
            "placeholder": "​",
            "style": "IPY_MODEL_8d52cfb6948e42bd99e2f75e3e3e3150",
            "value": " 836/836 [00:00&lt;00:00, 44.6kB/s]"
          }
        },
        "bc5d0ad4dec14e179a4992835d899875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9780acc95b524818967bfbf8d5f2c3be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c366c4118f8646e5b6d4bc85e8f668f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5420eab264d347a6a1282ae06199aa27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31b6c9555a2c4c37abdcd77b279d329a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc54375fda694fbbba7187d1374115dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d52cfb6948e42bd99e2f75e3e3e3150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c96e3c42a4c49eba7e5c39c6a77593d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b520f93e88ad44d2b6813f9f88dd5226",
              "IPY_MODEL_8b302a478a8844dfae4c6fb2833f2d2d",
              "IPY_MODEL_2835de45c9f34c54bd9db1d29714ca3a"
            ],
            "layout": "IPY_MODEL_472c38e9813c433bb7779013cc8d694c"
          }
        },
        "b520f93e88ad44d2b6813f9f88dd5226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b5954ba632a415a8e307a4ebe446490",
            "placeholder": "​",
            "style": "IPY_MODEL_0dd0891d7e434a32ba829abc72b2c856",
            "value": "model.safetensors: 100%"
          }
        },
        "8b302a478a8844dfae4c6fb2833f2d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad15ca54afac4b7fbaa7c5c24a51e54c",
            "max": 1995339680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb70fcf69bb543a797a78c6060a23e66",
            "value": 1995339680
          }
        },
        "2835de45c9f34c54bd9db1d29714ca3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0ec337708404056a822a8bb4c685bb0",
            "placeholder": "​",
            "style": "IPY_MODEL_3d9be9b01ce84f73a294d3059af692ea",
            "value": " 2.00G/2.00G [00:41&lt;00:00, 59.7MB/s]"
          }
        },
        "472c38e9813c433bb7779013cc8d694c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b5954ba632a415a8e307a4ebe446490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dd0891d7e434a32ba829abc72b2c856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad15ca54afac4b7fbaa7c5c24a51e54c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb70fcf69bb543a797a78c6060a23e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0ec337708404056a822a8bb4c685bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9be9b01ce84f73a294d3059af692ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/LLMOptCost/blob/main/PRUNING/pruning_structured_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries & Support functions."
      ],
      "metadata": {
        "id": "D2cQlEYYbfZ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t81oS3_sM2-I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.utils.prune as prune\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load  Hugging Face model\n",
        "base_model_name = \"gpt2\"\n",
        "pruned_model_name = \"gpt2-uncased-pruned\""
      ],
      "metadata": {
        "id": "tsJG05EwbOEX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(base_model_name)"
      ],
      "metadata": {
        "id": "NyavvDYY23IQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.config)"
      ],
      "metadata": {
        "id": "o-8LoqEiqrgN",
        "outputId": "66ec10cd-f9c3-447a-e4e5-16a34267a4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.44.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)"
      ],
      "metadata": {
        "id": "MUhNMt5I408O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "rsDclYm_8esX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_neuron_importance(mlp_layer):\n",
        "    # Access the first linear layer in the MLP\n",
        "    fc_in = mlp_layer.c_fc\n",
        "    weight = fc_in.weight.data  # Shape: (intermediate_size, hidden_size)\n",
        "\n",
        "    # Compute the L2 norm of each neuron (over input features)\n",
        "    neuron_importance = torch.norm(weight, p=2, dim=1)  # Shape: (intermediate_size,)\n",
        "\n",
        "    return neuron_importance"
      ],
      "metadata": {
        "id": "-F2D5y7H27GN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_neurons_to_prune(neuron_importance, pruning_percentage):\n",
        "    num_neurons = neuron_importance.size(0)\n",
        "    num_prune = int(num_neurons * pruning_percentage)\n",
        "\n",
        "    # Get indices of neurons sorted by importance\n",
        "    sorted_indices = torch.argsort(neuron_importance)\n",
        "\n",
        "    # Select indices to prune (least important neurons)\n",
        "    neurons_to_prune = sorted_indices[:num_prune]\n",
        "\n",
        "    return neurons_to_prune"
      ],
      "metadata": {
        "id": "rr34sn5R3CVA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_mlp_neurons(mlp_layer, neurons_to_prune):\n",
        "    # Access the MLP's linear layers\n",
        "    fc_in = mlp_layer.c_fc\n",
        "    fc_out = mlp_layer.c_proj\n",
        "\n",
        "    # Prune neurons in fc_in (input to MLP)\n",
        "    prune_linear_layer(fc_in, neurons_to_prune, dim=0)\n",
        "\n",
        "    # Prune corresponding neurons in fc_out (output of MLP)\n",
        "    prune_linear_layer(fc_out, neurons_to_prune, dim=1)"
      ],
      "metadata": {
        "id": "s2XzetWM4Q6C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_linear_layer(layer, indices_to_prune, dim=0):\n",
        "    \"\"\"\n",
        "    Prune specified indices from a linear layer along the given dimension.\n",
        "    \"\"\"\n",
        "    # Convert indices to keep\n",
        "    indices_to_keep = torch.tensor([\n",
        "        idx for idx in range(layer.weight.size(dim))\n",
        "        if idx not in set(indices_to_prune.tolist())\n",
        "    ])\n",
        "\n",
        "    # Prune weights\n",
        "    weight = layer.weight.data.index_select(dim, indices_to_keep)\n",
        "    layer.weight = torch.nn.Parameter(weight)\n",
        "\n",
        "    # Prune biases if necessary\n",
        "    if layer.bias is not None:\n",
        "        if dim == 0:\n",
        "            bias = layer.bias.data.index_select(0, indices_to_keep)\n",
        "            layer.bias = torch.nn.Parameter(bias)\n",
        "\n",
        "    # Update layer dimensions\n",
        "    if dim == 0:\n",
        "        layer.out_features = weight.size(0)\n",
        "    else:\n",
        "        layer.in_features = weight.size(1)"
      ],
      "metadata": {
        "id": "7tbWWSWe4Tzb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_mlp_neurons_in_model(model, pruning_percentage):\n",
        "    num_layers = model.config.n_layer\n",
        "\n",
        "    for layer_idx in range(num_layers):\n",
        "        # Access the MLP layer\n",
        "        mlp_layer = model.transformer.h[layer_idx].mlp\n",
        "\n",
        "        # Compute neuron importance\n",
        "        neuron_importance = compute_neuron_importance(mlp_layer)\n",
        "\n",
        "        # Select neurons to prune\n",
        "        neurons_to_prune = select_neurons_to_prune(neuron_importance, pruning_percentage)\n",
        "\n",
        "        # Prune neurons\n",
        "        prune_mlp_neurons(mlp_layer, neurons_to_prune)\n",
        "\n",
        "    # After pruning, update n_inner in the config\n",
        "    new_intermediate_size = model.transformer.h[0].mlp.c_fc.out_features\n",
        "    model.config.n_inner = new_intermediate_size\n"
      ],
      "metadata": {
        "id": "73SV2ED74Wz2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before pruning\n",
        "total_params_before = count_parameters(model)\n",
        "print(f\"Total parameters before pruning: {total_params_before}\")"
      ],
      "metadata": {
        "id": "NlGZcjNb8jEW",
        "outputId": "19de05f1-5414-4432-dabb-3a8043fa183e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters before pruning: 124439808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Paris is a\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "base_output = model.generate(**inputs)\n",
        "base_response = tokenizer.decode(base_output[0], skip_special_tokens=True)\n",
        "print(base_response)"
      ],
      "metadata": {
        "id": "d5lQCpJBRRnz",
        "outputId": "14f0ecf6-d302-48cd-bb11-88ede9bf3bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paris is a city of people, of people, of people. It's a place where people come\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prune Model"
      ],
      "metadata": {
        "id": "zxdwtDKhf01B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the pruning percentage (e.g., 20% pruning)\n",
        "pruning_percentage = 0.3  # Adjust as needed\n",
        "\n",
        "# Prune MLP neurons in the model\n",
        "prune_mlp_neurons_in_model(model, pruning_percentage)"
      ],
      "metadata": {
        "id": "yQuzCebT4aAH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modify Configuration & test pruned model"
      ],
      "metadata": {
        "id": "8J_3wqQNf4GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# After pruning\n",
        "total_params_after = count_parameters(model)\n",
        "print(f\"Total parameters after pruning: {total_params_after}\")\n",
        "\n",
        "# Calculate the number of parameters removed\n",
        "params_removed = total_params_before - total_params_after\n",
        "print(f\"Number of parameters removed: {params_removed}\")\n",
        "\n",
        "# Calculate percentage reduction\n",
        "percent_reduction = 100.0 * params_removed / total_params_before\n",
        "print(f\"Percentage reduction in parameters: {percent_reduction:.2f}%\")\n"
      ],
      "metadata": {
        "id": "z9G0QPYA8naZ",
        "outputId": "5d7b6a72-e124-4199-f2f7-bda476798252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters after pruning: 107451960\n",
            "Number of parameters removed: 16987848\n",
            "Percentage reduction in parameters: 13.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Tell me a joke\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "base_output = model.generate(**inputs)\n",
        "base_response = tokenizer.decode(base_output[0], skip_special_tokens=True)\n",
        "print(base_response)"
      ],
      "metadata": {
        "id": "jlomsST95xBN",
        "outputId": "e9679797-b5e6-4701-a6ba-d54884fb0a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (4x768 and 538x3072)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b08100b0f5db>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Tell me a joke\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbase_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbase_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1316\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1127\u001b[0m                 )\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m   1130\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x768 and 538x3072)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save & Upload Model"
      ],
      "metadata": {
        "id": "IXNjjL9gRsEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the quantized model\n",
        "model.save_pretrained(\n",
        "    \"bloomz-560m-pruned-structured3\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "JJrnO6ORRmKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"bloomz-560m-pruned-structured3\")"
      ],
      "metadata": {
        "id": "P9EvALTWTjEM",
        "outputId": "8b93b713-7aab-4f24-e6cd-46fad870a175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bloomz-560m-pruned-structured3/tokenizer_config.json',\n",
              " 'bloomz-560m-pruned-structured3/special_tokens_map.json',\n",
              " 'bloomz-560m-pruned-structured3/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"bloomz-560m-pruned-structured3\",\n",
        "                  private=True,\n",
        "                  use_temp_dir=False)"
      ],
      "metadata": {
        "id": "j0Hv_wLDUaAP",
        "outputId": "c32ad621-ae22-4629-f923-831e026b1971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "685acf5ba2544455a21cc692e8ea3df6",
            "ca5801f3a20f4fe2a077826514482406",
            "b79f441aa396408ea1efb2268900b0ff",
            "440c20eae7354d36a746cdc14bd56a56",
            "de544659a0604a46a360d75846c8595c",
            "4f027cbb89d64ad1b07e5bb2ac48cbf7",
            "a2ef8a9342c74f00ada72ccdb0fc6ef1",
            "56becc351a8c4742a8b7a37b7f5aa387",
            "00e9d9927f8545d79cc0bd164a208975",
            "6d19de2e86494b16bf29e829cfc8b33c",
            "8a933f0153bc4fe68b48fe038dba5a6a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "685acf5ba2544455a21cc692e8ea3df6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/oopere/bloomz-560m-pruned-structured3/commit/a021ec286c6125e5b8750f4fc001891940ac8503', commit_message='Upload BloomForCausalLM', commit_description='', oid='a021ec286c6125e5b8750f4fc001891940ac8503', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(\"bloomz-560m-pruned-structured3\",\n",
        "                      private=False,\n",
        "                      use_temp_dir=False)"
      ],
      "metadata": {
        "id": "WzRgQ_c0Ug8T",
        "outputId": "b5eb6a2d-a3dc-42fb-8b86-2a8e5114243e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "73686db455224648b2819a4e23b319eb",
            "8b6ff4523fac43408eec5d727bdbee57",
            "6a60f4ed522348218b828f9c47562343",
            "d7e11345f097435091354b4601a91b89",
            "41d196f1d24643f39358fe825a30a8df",
            "81857adb0d09419c87b0ebe10a333e6d",
            "9ee17e7f6c2d438eabdef904f9f496b1",
            "ae2f9ced51d24f3096fbf6e433f2902c",
            "4a481227d953469880ad36d7d0e3158e",
            "34c6272fa9ad4ba794f53df49aee5147",
            "22f6215920bf4582984c5b8c849e659f",
            "fa7282710eec4628b0da9a5805f27237",
            "864d67e6afe942799587015cf73db00d",
            "aa450c130f13414e94038ba8231f946c",
            "1d65b561ad324018a31bb79e6f1350b7",
            "eb56d4a9d8e442a483bdba3a979b6e53",
            "42c4da1a8e284c27a46e428a7bb5c107",
            "ee05cc45ecda4deb9fd7d9cc184f6fbd",
            "b759d0fcc2404925b14d795db4dc5f2d",
            "b2a65814cb514e4a9e250b906ac08502",
            "bac4279ff7bf4da6b9dd26d947565f54",
            "803da2ce0315404b8d553c9b69ccfeea"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73686db455224648b2819a4e23b319eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa7282710eec4628b0da9a5805f27237"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/oopere/bloomz-560m-pruned-structured3/commit/30657e1a9c83e8978d070bb686f794a0018e9dd4', commit_message='Upload tokenizer', commit_description='', oid='30657e1a9c83e8978d070bb686f794a0018e9dd4', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the pruned model from Hugging Face & Test."
      ],
      "metadata": {
        "id": "qusVr4RuZBIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_model_pruned_name = \"oopere/bloomz-560m-pruned-structured3\"\n",
        "model = AutoModelForCausalLM.from_pretrained(download_model_pruned_name)"
      ],
      "metadata": {
        "id": "gsq3wZ2uUlMf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1ce2504d701e47fdbff6c06392ca2446",
            "285d6f8cad0741669d72ce3374e1fcab",
            "23180435a0d44201bfe21bb8a8571f49",
            "50422043150a47a8995d442b36a83270",
            "bc5d0ad4dec14e179a4992835d899875",
            "9780acc95b524818967bfbf8d5f2c3be",
            "c366c4118f8646e5b6d4bc85e8f668f6",
            "5420eab264d347a6a1282ae06199aa27",
            "31b6c9555a2c4c37abdcd77b279d329a",
            "bc54375fda694fbbba7187d1374115dc",
            "8d52cfb6948e42bd99e2f75e3e3e3150",
            "5c96e3c42a4c49eba7e5c39c6a77593d",
            "b520f93e88ad44d2b6813f9f88dd5226",
            "8b302a478a8844dfae4c6fb2833f2d2d",
            "2835de45c9f34c54bd9db1d29714ca3a",
            "472c38e9813c433bb7779013cc8d694c",
            "7b5954ba632a415a8e307a4ebe446490",
            "0dd0891d7e434a32ba829abc72b2c856",
            "ad15ca54afac4b7fbaa7c5c24a51e54c",
            "bb70fcf69bb543a797a78c6060a23e66",
            "d0ec337708404056a822a8bb4c685bb0",
            "3d9be9b01ce84f73a294d3059af692ea"
          ]
        },
        "outputId": "d1a22d0e-39ae-42d8-a4a8-43744fcb0a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/836 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ce2504d701e47fdbff6c06392ca2446"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c96e3c42a4c49eba7e5c39c6a77593d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for BloomForCausalLM:\n\tsize mismatch for transformer.h.0.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.0.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.0.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.1.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.1.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.1.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.2.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.2.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.2.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.3.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.3.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.3.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.4.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.4.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.4.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.5.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.5.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.5.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.6.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.6.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.6.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.7.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.7.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.7.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.8.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.8.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.8.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.9.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.9.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.9.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.10.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.10.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.10.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.11.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.11.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.11.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.12.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.12.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.12.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.13.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.13.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.13.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.14.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.14.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.14.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.15.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.15.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.15.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.16.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.16.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.16.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.17.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.17.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.17.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.18.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.18.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.18.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.19.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.19.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.19.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.20.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.20.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.20.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.21.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.21.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.21.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.22.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.22.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.22.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.23.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.23.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.23.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-487653643bb2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdownload_model_pruned_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"oopere/bloomz-560m-pruned-structured3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_model_pruned_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3958\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3959\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3960\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3961\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3962\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4490\u001b[0m                     \u001b[0;34m\"\\n\\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m                 )\n\u001b[0;32m-> 4492\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error(s) in loading state_dict for {model.__class__.__name__}:\\n\\t{error_msg}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BloomForCausalLM:\n\tsize mismatch for transformer.h.0.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.0.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.0.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.1.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.1.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.1.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.2.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.2.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.2.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.3.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.3.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.3.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.4.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.4.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.4.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.5.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.5.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.5.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.6.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.6.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.6.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.7.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.7.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.7.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.8.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.8.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.8.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.9.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.9.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.9.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.10.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.10.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.10.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.11.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.11.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.11.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.12.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.12.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.12.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.13.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.13.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.13.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.14.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.14.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.14.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.15.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.15.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.15.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.16.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.16.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.16.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.17.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.17.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.17.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.18.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.18.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.18.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.19.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.19.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.19.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.20.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.20.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.20.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.21.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.21.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.21.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.22.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.22.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.22.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tsize mismatch for transformer.h.23.mlp.dense_h_to_4h.weight: copying a param with shape torch.Size([2868, 1024]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for transformer.h.23.mlp.dense_h_to_4h.bias: copying a param with shape torch.Size([2868]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for transformer.h.23.mlp.dense_4h_to_h.weight: copying a param with shape torch.Size([1024, 2868]) from checkpoint, the shape in current model is torch.Size([1024, 4096]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBfguGH-bYSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}